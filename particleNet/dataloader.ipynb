{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch import nn\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_df_path = '../data/particle_df.csv'\n",
    "particle_preproc_df_path = '../data/particle_df_preprocessed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventID</th>\n",
       "      <th>jetID</th>\n",
       "      <th>particleType</th>\n",
       "      <th>particleVx</th>\n",
       "      <th>particleVy</th>\n",
       "      <th>particleVz</th>\n",
       "      <th>particlePx</th>\n",
       "      <th>particlePy</th>\n",
       "      <th>particlePz</th>\n",
       "      <th>particleE</th>\n",
       "      <th>particlePolarPx</th>\n",
       "      <th>particlePolarPy</th>\n",
       "      <th>particlePolarPz</th>\n",
       "      <th>particlePolarE</th>\n",
       "      <th>particlePhi</th>\n",
       "      <th>particleTheta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-115.595071</td>\n",
       "      <td>5.513218</td>\n",
       "      <td>107.093643</td>\n",
       "      <td>157.675996</td>\n",
       "      <td>115.726471</td>\n",
       "      <td>0.827630</td>\n",
       "      <td>3.093935</td>\n",
       "      <td>2.347607e-01</td>\n",
       "      <td>3.093935</td>\n",
       "      <td>0.824122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-83.072377</td>\n",
       "      <td>4.831796</td>\n",
       "      <td>75.798599</td>\n",
       "      <td>112.561324</td>\n",
       "      <td>83.212776</td>\n",
       "      <td>0.816948</td>\n",
       "      <td>3.083494</td>\n",
       "      <td>5.078805e-01</td>\n",
       "      <td>3.083494</td>\n",
       "      <td>0.831991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-211</td>\n",
       "      <td>-0.981025</td>\n",
       "      <td>1.422285</td>\n",
       "      <td>-33.456345</td>\n",
       "      <td>-11.168506</td>\n",
       "      <td>-8.774579</td>\n",
       "      <td>9.043395</td>\n",
       "      <td>16.838385</td>\n",
       "      <td>14.203125</td>\n",
       "      <td>0.600055</td>\n",
       "      <td>-2.475661</td>\n",
       "      <td>1.395264e-01</td>\n",
       "      <td>-2.475661</td>\n",
       "      <td>1.003814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0.073932</td>\n",
       "      <td>0.089866</td>\n",
       "      <td>-2.399344</td>\n",
       "      <td>-8.233158</td>\n",
       "      <td>-1.087632</td>\n",
       "      <td>6.647210</td>\n",
       "      <td>10.637351</td>\n",
       "      <td>8.304688</td>\n",
       "      <td>0.732994</td>\n",
       "      <td>-3.010249</td>\n",
       "      <td>-1.192093e-07</td>\n",
       "      <td>-3.010249</td>\n",
       "      <td>0.895801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-211</td>\n",
       "      <td>0.073905</td>\n",
       "      <td>0.089409</td>\n",
       "      <td>-2.399101</td>\n",
       "      <td>-8.048296</td>\n",
       "      <td>0.478376</td>\n",
       "      <td>6.097900</td>\n",
       "      <td>10.109785</td>\n",
       "      <td>8.062500</td>\n",
       "      <td>0.698202</td>\n",
       "      <td>3.082224</td>\n",
       "      <td>1.395264e-01</td>\n",
       "      <td>3.082224</td>\n",
       "      <td>0.923257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eventID  jetID  particleType  particleVx  particleVy  particleVz  \\\n",
       "0        0      0             0    0.000000    0.000000    0.000000   \n",
       "1        0      0             0    0.000000    0.000000    0.000000   \n",
       "2        0      0          -211   -0.981025    1.422285  -33.456345   \n",
       "3        0      0           130    0.073932    0.089866   -2.399344   \n",
       "4        0      0          -211    0.073905    0.089409   -2.399101   \n",
       "\n",
       "   particlePx  particlePy  particlePz   particleE  particlePolarPx  \\\n",
       "0 -115.595071    5.513218  107.093643  157.675996       115.726471   \n",
       "1  -83.072377    4.831796   75.798599  112.561324        83.212776   \n",
       "2  -11.168506   -8.774579    9.043395   16.838385        14.203125   \n",
       "3   -8.233158   -1.087632    6.647210   10.637351         8.304688   \n",
       "4   -8.048296    0.478376    6.097900   10.109785         8.062500   \n",
       "\n",
       "   particlePolarPy  particlePolarPz  particlePolarE  particlePhi  \\\n",
       "0         0.827630         3.093935    2.347607e-01     3.093935   \n",
       "1         0.816948         3.083494    5.078805e-01     3.083494   \n",
       "2         0.600055        -2.475661    1.395264e-01    -2.475661   \n",
       "3         0.732994        -3.010249   -1.192093e-07    -3.010249   \n",
       "4         0.698202         3.082224    1.395264e-01     3.082224   \n",
       "\n",
       "   particleTheta  \n",
       "0       0.824122  \n",
       "1       0.831991  \n",
       "2       1.003814  \n",
       "3       0.895801  \n",
       "4       0.923257  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_pre_df = pd.read_csv(particle_preproc_df_path)\n",
    "par_df = pd.read_csv(particle_df_path)\n",
    "par_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleDataset(Dataset):\n",
    "    # The ParticleDataset class inherits the Dataset class and implements the __init__, __len__, and __getitem__ methods\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        # Initializing the ParticleDataset object.\n",
    "        # \"path\" is the path to the csv file containing the particle data.\n",
    "        # \"transform\" is an optional argument that specifies the transformations to be applied to the data.\n",
    "\n",
    "        # Read the csv file into a Pandas DataFrame.\n",
    "        self.x = pd.read_csv(path)\n",
    "\n",
    "        # Put the coordinates eta and phi as the first two features\n",
    "        self.x = self.x.reindex(\n",
    "            columns=[\"particlePolarPy\", \"particlePhi\"]\n",
    "            + [\n",
    "                col\n",
    "                for col in self.x.columns\n",
    "                if col not in [\"particlePolarPy\", \"particlePhi\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Store the \"transform\" argument.\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of particles in the dataset.\n",
    "        \"\"\"\n",
    "        # Return the number of rows in the DataFrame (i.e., the number of particles).\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the particles with jetID = idx.\n",
    "        \"\"\"\n",
    "        # Get the rows in the DataFrame that have a \"jetID\" column equal to \"idx\".\n",
    "        x = self.x[self.x.jetID==idx].to_numpy()\n",
    "        \n",
    "        # If \"transform\" was specified, apply it to the data.\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        # Return the transformed data.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 16])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Compose object that applies the \"ToTensor\" transformation.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# Create a ParticleDataset object using the csv file located at \"particle_df_path\" and the \"train_transform\" transformations.\n",
    "train_data = ParticleDataset(particle_df_path, train_transform)\n",
    "\n",
    "# Access the first element in the dataset to get its shape.\n",
    "train_data[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Dataset on the KNN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 10, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kNN(x,k=10):\n",
    "\n",
    "    # expand the input tensor s.t. x_knn.shape = [B, n, n, d]\n",
    "    x_knn = x.unsqueeze(1).expand(-1, x.shape[1], -1, -1)\n",
    "\n",
    "    # calculate both delta_phi and delta_eta, with the transpose we get every pair\n",
    "    delta_phieta = x_knn[:, :, :, :2] - x_knn[:, :, :, :2].transpose(1, 2)\n",
    "\n",
    "    # calculate distances and sort them in ascending order, keep only the indeces\n",
    "    _, indeces = torch.sqrt(torch.sum(delta_phieta**2, 3)**0.5).sort(dim=2, stable=True)\n",
    "\n",
    "    # keep the indeces of k nearest neighbours and use them to sort and cut the initial tensor\n",
    "    knn = indeces[:,:,:k]\n",
    "    x_knn = torch.gather(x_knn, 2, knn.unsqueeze(-1).expand(-1, -1, -1, x_knn.shape[-1]))\n",
    "\n",
    "    del delta_phieta, indeces, knn, _\n",
    "\n",
    "    return x_knn\n",
    "\n",
    "kNN(train_data[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    \"\"\"\n",
    "    A custom collate function that can handle different shape tensors.\n",
    "    The default collate function provided by PyTorch's DataLoader assumes that all tensors in a batch have the same shape. \n",
    "    However, in our case, each \"datum\" is a set of particles that compose a jet and the number of particles composing a jet is not fixed. \n",
    "    Therefore, each tensor representing a jet has a different shape.\n",
    "\n",
    "    To handle this scenario, we need to override the collate function to be able to stack the tensors into a batch. \n",
    "    This function first determines the maximum number of particles among all jets in the batch. \n",
    "    Then, it pads all tensors with zeros to make sure they have the same shape. \n",
    "    Finally, it stacks the tensors along the batch dimension to return the padded data and original lengths.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the max number of particles among all the jets in the batch\n",
    "    n_part_max = max(x.shape[1] for x in batch)\n",
    "\n",
    "    # Pad all the tensors with zeros so they have the same shape\n",
    "    data = []\n",
    "    lengths = []\n",
    "    for x in batch:\n",
    "        n_part = x.shape[1]\n",
    "        data.append(torch.cat([x, torch.zeros(1, n_part_max - n_part, 16)], dim=1))\n",
    "        lengths.append(n_part)\n",
    "\n",
    "    # Stack the tensors along the batch dimension\n",
    "    data = torch.stack(data)\n",
    "\n",
    "    # Return the padded data, original lengths, and target labels\n",
    "    return data, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size       = 10\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 62, 16]) [23, 41, 26, 20, 62, 35, 9, 4, 46, 48]\n",
      "torch.Size([10, 1, 66, 16]) [41, 22, 2, 40, 21, 26, 25, 66, 28, 2]\n"
     ]
    }
   ],
   "source": [
    "# loop over the dataloader to get the data in batches\n",
    "i=0\n",
    "for batch, original_length in train_dataloader:\n",
    "    print(batch.shape, original_length)\n",
    "    i+=1\n",
    "    if i==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the forward pass of your model, you can use the original lengths to process the data correctly, for example, by masking out the padded zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing nested tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = []\n",
    "\n",
    "for i, original_shape in enumerate(original_length):\n",
    "    # Slice the tensor along the third dimension to get the desired shape\n",
    "    a = batch[i, :, :original_shape, :]\n",
    "    tensors.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 41, 16])\n",
      "torch.Size([1, 22, 16])\n",
      "torch.Size([1, 2, 16])\n",
      "torch.Size([1, 40, 16])\n",
      "torch.Size([1, 21, 16])\n",
      "torch.Size([1, 26, 16])\n",
      "torch.Size([1, 25, 16])\n",
      "torch.Size([1, 66, 16])\n",
      "torch.Size([1, 28, 16])\n",
      "torch.Size([1, 2, 16])\n"
     ]
    }
   ],
   "source": [
    "for t in tensors:\n",
    "    print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'nested'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-8b10c35c7eb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnested\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnested\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnested_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'nested'"
     ]
    }
   ],
   "source": [
    "nested = torch.nested.nested_tensor(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 16])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested[2].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the edge conv block functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 23, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_data[0]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(x, k=10):\n",
    "    \"\"\"input: single jet data\n",
    "        output: tensor with shape [B, n, k, d] where d are the features of the knn particles\"\"\"\n",
    "    # expand the input tensor s.t. x_knn.shape = [B, n, n, d]\n",
    "    x_knn = x.unsqueeze(1).expand(-1, x.shape[1], -1, -1)\n",
    "\n",
    "    # calculate both delta_phi and delta_eta\n",
    "    delta_phieta = x_knn[:, :, :, :2] - x_knn[:, :, :, :2].transpose(1, 2)\n",
    "\n",
    "    # calculate distances and sort them in ascending order, keep only the indeces\n",
    "    _, indeces = torch.sqrt(torch.sum(delta_phieta**2, 3)**0.5).sort(dim=2, stable=True)\n",
    "\n",
    "    # keep the indeces of k nearest neighbours and use them to sort and cut the initial tensor\n",
    "    knn = indeces[:,:,:k]\n",
    "    x_knn = torch.gather(x_knn, 2, knn.unsqueeze(-1).expand(-1, -1, -1, x_knn.shape[-1]))\n",
    "\n",
    "    del delta_phieta, indeces, knn, _\n",
    "\n",
    "    return x_knn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([23, 10, 16])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_knn = kNN(x)\n",
    "x_knn.shape\n",
    "\n",
    "x_knn_batch = x_knn[0]\n",
    "x_knn_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_aggregate(x):\n",
    "\n",
    "    '''Applico ad un solo batch!! --> shape finale aspettata  [n,d] '''\n",
    "\n",
    "    # Here we want to define the operation which applies the mlp,\n",
    "    # i.e. the linear part, to each couple of n.n. and then\n",
    "    # aggregates the results.\n",
    "    # Expected output shape is [B, n, d] (aggregating we collapsed the k dimension)\n",
    "\n",
    "    '''Concateniamo le Features di due nearest neighbours, \n",
    "        passiamo questo Array alla parte lineare, \n",
    "        ripetiamo l'operazione per tutte le coppie di particella iesima e suo nearest neighbours,\n",
    "        facciamo max o softmax su queste\n",
    "    '''\n",
    "    # for b in range(x.shape[0]): # scorro sui batch\n",
    "    for p in range(x.shape[0]): # fisso una particella\n",
    "        p_feat   = x[p, :, :] # features dei nn di p\n",
    "\n",
    "        p_feat   = x[b, p, 0, :].unsqueeze(0)\n",
    "        knn_feat = x[b, p, :, :]\n",
    "        pairs = torch.stack(p_feat, knn_feat, dim = 0)\n",
    "        \n",
    "        print(p_feat.shape)\n",
    "        break\n",
    "        # pairs = torch.stack([torch.stack([p_feat[0, :], p_feat[i, :]]) for i in range(0, x.shape[1])])\n",
    "        difference = p_feat - p_feat[0,:]\n",
    "        difference = difference[1:,:]\n",
    "\n",
    "        # print(\"pairs of the particle \",p, \"is\",pairs.shape) #expected [k, 2, d]\n",
    "        print(\"shape of the differences between p and its nn: (expected [k,d])\")\n",
    "\n",
    "        mlp_pair_list = []\n",
    "        \n",
    "        # ciclo per accedere alle coppie\n",
    "        for i in range(pairs.shape[0]):\n",
    "            y = (pairs[i, :, :])**2 # give to the MLP part a 2D tensor of shape [2,d]\n",
    "            mlp_pair_list.append(y) # list of the i-esim particle with every its pairs\n",
    "        \n",
    "        print(\"len of pair list\",len(mlp_pair_list)) # expected = k perchè sono il numero di coppie\n",
    "\n",
    "        mlp_pair = torch.stack(mlp_pair_list) # aggregate all the pairs of the i-esim particle p\n",
    "        print(\"shape of all pairs output of layers\",mlp_pair.shape) # expected [k, 2, d]\n",
    "\n",
    "    particles_per_jet = torch.stack(mlp_pair) # aggregate all the particles of the jet\n",
    "    \n",
    "    '''\n",
    "    QUA CI SAREBBE IL SOFTMAX\n",
    "\n",
    "    '''\n",
    "    print(particles_per_jet.shape) # in this example (fixing the batch), we expect a shape [n,d]\n",
    "    '''each particle have its features'''\n",
    "\n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4efe3a437f6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlinear_aggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_knn_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-a583d29a8a0c>\u001b[0m in \u001b[0;36mlinear_aggregate\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mp_feat\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# features dei nn di p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mp_feat\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mknn_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mpairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "linear_aggregate(x_knn_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_aggregate(x):\n",
    "\n",
    "    '''Applico ad un solo batch!! --> shape finale aspettata  [n,d] '''\n",
    "\n",
    "    # for b in range(x.shape[0]): # scorro sui batch\n",
    "    \n",
    "    edge_of_p  = [] # lista per le edges della particella\n",
    "\n",
    "    for p in range(x.shape[0]): # fisso una particella\n",
    "        \n",
    "        # p_feat   = x[p, :, :] # features dei nn di p\n",
    "\n",
    "        p_feat   = x[p, 0, :].unsqueeze(0).expand(x.shape[1], -1)\n",
    "\n",
    "        #DIFFERENCES \n",
    "\n",
    "        knn_feat = x[p, :, :] - p_feat\n",
    "\n",
    "        pairs = torch.concat([p_feat, knn_feat], dim=1)\n",
    "\n",
    "\n",
    "        print(\"shape of the knn_feats between p and its nn: (expected [k,2*d])\", pairs.shape)\n",
    "\n",
    "        mlp_list = []\n",
    "        \n",
    "        # ciclo per accedere alla singola riga \n",
    "        # -> passo una singola riga alla volta al MLP e salvo in una lista\n",
    "\n",
    "        for i in range(pairs.shape[0]):\n",
    "            y = (pairs[i, :])**2 # give to the MLP part a 2D tensor of shape [1,d] \n",
    "                                    # -> output expected [1,channels]\n",
    "            mlp_list.append(y) # list of the i-esim particle with every its pairs\n",
    "        \n",
    "        # print(\"len of pair list\",len(mlp_list)) # expected = k perchè sono il numero di coppie\n",
    "    \n",
    "        mlp_result = torch.stack(mlp_list) # aggregate all the pairs of the i-esim particle p\n",
    "        max, _ = torch.max(mlp_result, dim=0) # take the maximum row \n",
    "\n",
    "        ##### possiamo prendere anche avg o sum #####\n",
    "        \n",
    "        # print(\"shape of all pairs output of layers\",mlp_result.shape) # expected [k, d] or [k, ch]\n",
    "        # print(\"shape of all pairs output of layers\",max.shape) # expected [1, d] or [1, ch]\n",
    "        \n",
    "        edge_of_p.append(max) # append the edges of the p particle\n",
    "\n",
    "        del mlp_list\n",
    "        \n",
    "    print(len(edge_of_p), \"expected n =\",x.shape[0])\n",
    "\n",
    "    edges = torch.stack(edge_of_p)\n",
    "    print(\"shape of edges:\", edges.shape, \"expected [\",x.shape[0],\", ch]\")\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "shape of the knn_feats between p and its nn: (expected [k,2*d]) torch.Size([10, 32])\n",
      "23 expected n = 23\n",
      "shape of edges: torch.Size([23, 32]) expected [ 23 , ch]\n"
     ]
    }
   ],
   "source": [
    "linear_aggregate(x_knn_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3.]])\n",
      "torch.Size([3])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor di shape [10,16]\n",
    "tensor = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float32)\n",
    "\n",
    "# Calcola la differenza tra la prima riga e tutte le altre righe\n",
    "differences = tensor - tensor[0,:]\n",
    "\n",
    "# Rimuovi la prima riga (che è uguale alla prima riga originale)\n",
    "result = differences[1:,:]\n",
    "\n",
    "print(result)\n",
    "print(differences[1,:].shape)\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[[4., 5., 6.],\n",
      "         [4., 5., 6.],\n",
      "         [4., 5., 6.]]])\n",
      "tensor([[4., 5., 6.],\n",
      "        [4., 5., 6.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([1, 1, 1])\n",
      "\n",
      "\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Tensor di shape [10,16]\n",
    "tensor = torch.tensor([[1,2,3],[4,5,6]], dtype=torch.float32)\n",
    "print(tensor.shape)\n",
    "# Trova la riga con i valori massimi\n",
    "max_index = tensor.argmax(dim=0)\n",
    "max_row = tensor[max_index,:]\n",
    "max, _ = torch.max(tensor, dim=0)\n",
    "# Riduci la riga a [1,16]\n",
    "result = max_row.unsqueeze(0)\n",
    "\n",
    "print(result)\n",
    "print(max_row)\n",
    "print(max_index)\n",
    "print(\"\\n\")\n",
    "print(max.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60560e0d6226cb5287d81368c04acd3a7e9c5751a6dd0763b56dc9cf4b259ada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
