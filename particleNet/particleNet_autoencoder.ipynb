{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # this module is useful to plot progress bars\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from DataReader import DataReader\n",
    "\n",
    "from particlenet import ParticleNet\n",
    "from particlenet_decoder import ParticleNetDecoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_reader, n_files=None, transform=None):\n",
    "\n",
    "        data_reader.read_files(n_files=n_files)\n",
    "\n",
    "        self.x = data_reader.get_features()\n",
    "        self.y = data_reader.get_labels()\n",
    "\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file jetImage_0_100p_0_10000.h5\n",
      "Reading file jetImage_0_100p_10000_20000.h5\n",
      "Reading file jetImage_0_100p_20000_30000.h5\n",
      "Reading file jetImage_0_100p_30000_40000.h5\n",
      "Reading file jetImage_0_100p_40000_50000.h5\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "data_reader = DataReader(\"../data/train/\")\n",
    "\n",
    "train_data = ParticleDataset(data_reader=data_reader, n_files=5, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 100, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size       = 64\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ParticleNet(7, 4)\n",
    "decoder = ParticleNetDecoder(4, 100, 7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ParticleNetDecoder(\n",
       "  (latent_to_up): Sequential(\n",
       "    (0): Softmax(dim=0)\n",
       "    (1): Linear(in_features=4, out_features=256, bias=True)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (edgeconvs): Sequential(\n",
       "    (0): EdgeConv(\n",
       "      (act): ReLU()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): EdgeConv(\n",
       "      (act): ReLU()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): EdgeConv(\n",
       "      (act): ReLU()\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv1d(64, 7, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (mlp): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(64, 7, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (7): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (8): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LinearLR, ExponentialLR\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr = 3e-4 # Learning rate\n",
    "\n",
    "#function for the custom learning rate:\n",
    "def custom_lr(epoch, lr = 3e-4):\n",
    "\n",
    "    if epoch < 8: # linear increase\n",
    "        return lr + 1.125e-4 * epoch\n",
    "    if (epoch >= 8 and epoch < 16): # linear decrease\n",
    "        return lr*10 - 1.125e-4 * (epoch - 8 )\n",
    "    if epoch >= 16: # linear decrease\n",
    "        return lr - 7.4825e-5 * (epoch - 16)\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=custom_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    # abbiamo gi√† definito l'optimizer nella cella precedente\n",
    "    \n",
    "    losses = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        #encode\n",
    "        y_encoder_pred = encoder(batch)\n",
    "        #decode\n",
    "        y_decoder_pred = decoder(y_encoder_pred)\n",
    "\n",
    "        loss = loss_fn(y_decoder_pred, batch) # funziona anche per le matrici in teoria\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # scheduler.step() # in teoria questo va alla fine di una epoca\n",
    "        \n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    losses = np.mean(losses)\n",
    "    return losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch(encoder, decoder, device, dataloader, loss_fn):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        for image_batch, _ in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = image_batch.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_batch)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_fn(conc_out, conc_label)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/20\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.cuda.DoubleTensor{[64, 1, 1, 100, 7]}, size=[-1, 1, -1, -1]): the number of sizes provided (4) must be greater or equal to the number of dimensions in the tensor (5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEPOCH \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, num_epochs))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m### Training (use the training function)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m train_loss \u001b[39m=\u001b[39m train_epoch(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     encoder\u001b[39m=\u001b[39;49mencoder, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     decoder\u001b[39m=\u001b[39;49mdecoder, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     device\u001b[39m=\u001b[39;49mdevice, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     dataloader\u001b[39m=\u001b[39;49mtrain_dataloader, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     loss_fn\u001b[39m=\u001b[39;49mloss_fn, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptim)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTRAIN - EPOCH \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m - loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m### Validation  (use the testing function)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mval_loss = test_epoch(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mprint(f'VALIDATION - EPOCH {epoch+1}/{num_epochs} - loss: {val_loss}\\n')\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n",
      "\u001b[1;32m/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb Cell 15\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(encoder, decoder, device, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#encode\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y_encoder_pred \u001b[39m=\u001b[39m encoder(batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#decode\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/alberto/Desktop/PoD/NNDL/jet-tagging/particleNet/particleNet_autoencoder.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m y_decoder_pred \u001b[39m=\u001b[39m decoder(y_encoder_pred)\n",
      "File \u001b[0;32m/media/alberto/Volume/Kubuntu/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/alberto/Volume/Kubuntu/PoD/NNDL/jet-tagging/particleNet/particlenet.py:29\u001b[0m, in \u001b[0;36mParticleNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 29\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_conv(x)\n\u001b[1;32m     30\u001b[0m     y \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mAvgPool1d(kernel_size\u001b[39m=\u001b[39my\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)(y\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m))\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     31\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinal_part(y)\n",
      "File \u001b[0;32m/media/alberto/Volume/Kubuntu/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/alberto/Volume/Kubuntu/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/media/alberto/Volume/Kubuntu/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/alberto/Volume/Kubuntu/PoD/NNDL/jet-tagging/particleNet/edgeconv.py:103\u001b[0m, in \u001b[0;36mEdgeConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    100\u001b[0m     \u001b[39m# x.size = [B, n, d]\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39m# x_knn.size = [B, n, k, d]\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     x_knn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkNN(x)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m    104\u001b[0m     shortcut \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshortcut(x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m))\n\u001b[1;32m    105\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear_aggregate(x_knn)\n",
      "File \u001b[0;32m/media/alberto/Volume/Kubuntu/PoD/NNDL/jet-tagging/particleNet/edgeconv.py:57\u001b[0m, in \u001b[0;36mEdgeConv.kNN\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m\"\"\"input: single jet data\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    output: tensor with shape [B, n, k, d] where d are the features of the knn particles\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# expand the input tensor s.t. x_knn.shape = [B, n, n, d]\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m x_knn \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mexpand(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, x\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     59\u001b[0m \u001b[39m# calculate both delta_phi and delta_eta\u001b[39;00m\n\u001b[1;32m     60\u001b[0m delta_phieta \u001b[39m=\u001b[39m x_knn[:, :, :, :\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m x_knn[:, :, :, :\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.cuda.DoubleTensor{[64, 1, 1, 100, 7]}, size=[-1, 1, -1, -1]): the number of sizes provided (4) must be greater or equal to the number of dimensions in the tensor (5)"
     ]
    }
   ],
   "source": [
    "### Training cycle\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "    ### Training (use the training function)\n",
    "    train_loss = train_epoch(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=train_dataloader, \n",
    "        loss_fn=loss_fn, \n",
    "        optimizer=optim)\n",
    "    print(f'TRAIN - EPOCH {epoch+1}/{num_epochs} - loss: {train_loss}')\n",
    "    '''\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=test_dataloader, \n",
    "        loss_fn=loss_fn)\n",
    "    # Print Validationloss\n",
    "    print(f'VALIDATION - EPOCH {epoch+1}/{num_epochs} - loss: {val_loss}\\n')\n",
    "    '''\n",
    "    ### step of the lr scheduler\n",
    "    scheduler.step() # alla fine di ogni epoca\n",
    "\n",
    "    ### Plot progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "331a419315a2fdb77d716bff9d27d64bbb9fafc97272ccf1eb9acf778ff8f493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
