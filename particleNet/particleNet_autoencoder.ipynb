{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm # this module is useful to plot progress bars\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from DataReader import DataReader\n",
    "\n",
    "from particlenet import ParticleNet\n",
    "from particlenet_decoder import ParticleNetDecoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParticleDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_reader, n_files=None, transform=None):\n",
    "\n",
    "        data_reader.read_files(n_files=n_files)\n",
    "\n",
    "        self.x = data_reader.get_features()\n",
    "        self.y = data_reader.get_labels()\n",
    "\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file jetImage_0_100p_0_10000.h5\n",
      "Reading file jetImage_0_100p_10000_20000.h5\n",
      "Reading file jetImage_0_100p_20000_30000.h5\n",
      "Reading file jetImage_0_100p_30000_40000.h5\n",
      "Reading file jetImage_0_100p_40000_50000.h5\n"
     ]
    }
   ],
   "source": [
    "train_transform = None #transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "data_reader = DataReader(\"../data/train/\")\n",
    "\n",
    "train_data = ParticleDataset(data_reader=data_reader, n_files=5, transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 100, 7]), torch.float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size       = 64\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "\n",
    "next(iter(train_dataloader))[0].shape, next(iter(train_dataloader))[0].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ParticleNet(7, 4)\n",
    "decoder = ParticleNetDecoder(4, 100, 7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    }
   ],
   "source": [
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LinearLR, ExponentialLR\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr = 3e-4 # Learning rate\n",
    "\n",
    "#function for the custom learning rate:\n",
    "def custom_lr(epoch, lr = 3e-4):\n",
    "\n",
    "    if epoch < 8: # linear increase\n",
    "        return lr + 1.125e-4 * epoch\n",
    "    if (epoch >= 8 and epoch < 16): # linear decrease\n",
    "        return lr*10 - 1.125e-4 * (epoch - 8 )\n",
    "    if epoch >= 16: # linear decrease\n",
    "        return lr - 7.4825e-5 * (epoch - 16)\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=custom_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    # abbiamo gi√† definito l'optimizer nella cella precedente\n",
    "    \n",
    "    losses = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for batch, _ in tqdm(dataloader, 'Step'): # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        \n",
    "        batch = batch.to(device)\n",
    "        #encode\n",
    "        y_encoder_pred = encoder(batch)\n",
    "        #decode\n",
    "        y_decoder_pred = decoder(y_encoder_pred)\n",
    "\n",
    "        loss = loss_fn(y_decoder_pred, batch) # funziona anche per le matrici in teoria\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    \n",
    "    losses = np.mean(losses)\n",
    "    return losses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch(encoder, decoder, device, dataloader, loss_fn):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        for image_batch, _ in tqdm(dataloader, 'Step'):\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = image_batch.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_batch)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_fn(conc_out, conc_label)\n",
    "    return val_loss.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5131e214776f4b78a991d770d108119d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Step:   0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Training cycle\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    print('EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "    ### Training (use the training function)\n",
    "    train_loss = train_epoch(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=train_dataloader, \n",
    "        loss_fn=loss_fn, \n",
    "        optimizer=optim)\n",
    "    print(f'TRAIN - EPOCH {epoch+1}/{num_epochs} - loss: {train_loss}')\n",
    "    '''\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=test_dataloader, \n",
    "        loss_fn=loss_fn)\n",
    "    # Print Validationloss\n",
    "    print(f'VALIDATION - EPOCH {epoch+1}/{num_epochs} - loss: {val_loss}\\n')\n",
    "    '''\n",
    "    ### step of the lr scheduler\n",
    "    scheduler.step() # alla fine di ogni epoca\n",
    "\n",
    "    ### Plot progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 100, 7])\n"
     ]
    }
   ],
   "source": [
    "for batch, _ in train_dataloader:\n",
    "    print(batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "331a419315a2fdb77d716bff9d27d64bbb9fafc97272ccf1eb9acf778ff8f493"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
