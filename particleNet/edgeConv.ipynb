{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop EdgeConvBlock as a DNN layer in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd # this module is useful to work with tabular data\n",
    "import random # this module will be used to select random samples from a collection\n",
    "import os # this module will be used just to create directories in the local filesystem\n",
    "from tqdm.notebook import tqdm # this module is useful to plot progress bars\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN function\n",
    "this function modifies the input tensor adding a dimension of size $k$ in order to store the informations about nearest neighbours, where $k$ is the number of nearest neighbours we want to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_opt(k, x):\n",
    "    \n",
    "    x_knn = x.unsqueeze(1).expand(-1, x.shape[1], -1, -1)\n",
    "    delta_phieta = x_knn[:, :, :, :2] - x_knn[:, :, :, :2].transpose(1, 2)\n",
    "    _, indeces = torch.sqrt(torch.sum(delta_phieta**2, 3)**0.5).sort(dim=2, stable=True)\n",
    "    knn = indeces[:,:,:k]\n",
    "    x_knn = torch.gather(x_knn, 2, knn.unsqueeze(-1).expand(-1, -1, -1, x_knn.shape[-1]))\n",
    "    del delta_phieta, indeces, knn, _\n",
    "    return x_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test cases pass\n"
     ]
    }
   ],
   "source": [
    "def test_kNN():\n",
    "    x = torch.tensor([[[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]],\n",
    "                      [[7.0, 8.0], [9.0, 10.0], [11.0, 12.0]]])\n",
    "    k = 2\n",
    "\n",
    "    knn = kNN_opt(k, x)\n",
    "    expected = torch.tensor([[[[1.0, 2.0], [3.0, 4.0]],   [[3.0, 4.0], [1.0, 2.0]],  [[5.0, 6.0], [3.0, 4.0]]],\n",
    "                             [[[7.0, 8.0], [9.0, 10.0]],  [[9.0, 10.0], [7.0, 8.0]], [[11.0, 12.0], [9.0, 10.0]]]])\n",
    "    assert torch.allclose(knn, expected), f'Expected {expected}, but got {knn}'\n",
    "\n",
    "\n",
    "test_kNN()\n",
    "print('All test cases pass')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EdgeConv Block\n",
    "Define the Edge Convolution operation as a `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Edge Convolution Block ###########\n",
    "# The root block of our DNN.\n",
    "# Initialized by:\n",
    "#   - d     the number of features\n",
    "#   - k     number of nearest neighbours to consider in the concolution\n",
    "#   - C     a list-like or an int with the number of neurons of the three linear layers\n",
    "#   - aggr  the aggregation function, must be symmetric\n",
    "\n",
    "class EdgeConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, d, k, C, aggr=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if type(C) == int:\n",
    "            self.C = [C]*3\n",
    "        else:\n",
    "            self.C = C\n",
    "        \n",
    "        self.k = k\n",
    "\n",
    "        if aggr is None:\n",
    "            self.aggr = None\n",
    "        else:\n",
    "            self.aggr = aggr\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "\n",
    "        ### Shortcut path\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv1d(d, C[-1], 1, 1),\n",
    "            nn.BatchNorm1d(C[-1])\n",
    "        )\n",
    "\n",
    "        ### Linear section, approximation of a MLP\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d, C[0]),\n",
    "            nn.BatchNorm1d(C[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(C[0], C[1]),\n",
    "            nn.BatchNorm1d(C[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(C[1], C[2]),\n",
    "            nn.BatchNorm1d(C[2]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def kNN(self, x):\n",
    "        \"\"\"input: single jet data\n",
    "            output: tensor with shape [B, n, k, d] where d are the features of the knn particles\"\"\"\n",
    "        # expand the input tensor s.t. x_knn.shape = [B, n, n, d]\n",
    "        x_knn = x.unsqueeze(1).expand(-1, x.shape[1], -1, -1)\n",
    "\n",
    "        # calculate both delta_phi and delta_eta\n",
    "        delta_phieta = x_knn[:, :, :, :2] - x_knn[:, :, :, :2].transpose(1, 2)\n",
    "\n",
    "        # calculate distances and sort them in ascending order, keep only the indeces\n",
    "        _, indeces = torch.sqrt(torch.sum(delta_phieta**2, 3)**0.5).sort(dim=2, stable=True)\n",
    "\n",
    "        # keep the indeces of k nearest neighbours and use them to sort and cut the initial tensor\n",
    "        knn = indeces[:,:,:self.k]\n",
    "        x_knn = torch.gather(x_knn, 2, knn.unsqueeze(-1).expand(-1, -1, -1, x_knn.shape[-1]))\n",
    "\n",
    "        del delta_phieta, indeces, knn, _\n",
    "\n",
    "        return x_knn    # x_knn.shape = [B, n, k, d]\n",
    "\n",
    "    \n",
    "    def linear_aggregate(self, x):\n",
    "\n",
    "        # Here we want to define the operation which applies the mlp,\n",
    "        # i.e. the linear part, to each couple of n.n. and then\n",
    "        # aggregates the results.\n",
    "        # Expected output shape is [B, n, d] (aggregating we collapsed the k dimension)\n",
    "\n",
    "        '''Concateniamo le Features di due nearest neighbours, \n",
    "            passiamo questo Array alla parte lineare, \n",
    "            ripetiamo l'operazione per tutte le coppie di particella iesima e suo nearest neighbours,\n",
    "            facciamo max o softmax su queste\n",
    "        '''\n",
    "        for b in range(x.shape[0]): # scorro sui batch\n",
    "            for p in range(x.shape[1]): # fisso una particella\n",
    "                p_feat   = x[b, p, 0, :].unsqueeze(0)\n",
    "                knn_feat = x[b, p, :, :]\n",
    "                pairs = torch.stack(p_feat, knn_feat, dim = 1)\n",
    "        \n",
    "                mlp_pair_list = []\n",
    "                # ciclo per accedere alle coppie\n",
    "                for i in range(pairs.shape[0]):\n",
    "                    y = self.mlp(pairs[i, :, :])\n",
    "                    mlp_pair_list.append(y) # list of the i-esim particle with every its pairs\n",
    "        \n",
    "                mlp_pair = torch.stack(mlp_pair_list, dim=0) # aggregate all the pairs of the i-esim particle p\n",
    "\n",
    "            particles_per_jet = torch.stack(mlp_pair, dim=0) # aggregate all the particles of the jet\n",
    "        \n",
    "        \n",
    "        return torch.softmax(mlp_pair)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.size = [B, n, d]\n",
    "\n",
    "        # x_knn.size = [B, n, k, d]\n",
    "        x_knn = self.kNN(x)\n",
    "\n",
    "        shortcut = self.shortcut(x)\n",
    "        x = self.linear_aggregate(x_knn)\n",
    "\n",
    "        x = self.act(x + shortcut)\n",
    "        \n",
    "        del x_knn, shortcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_aggregate(self, x):\n",
    "\n",
    "    # Here we want to define the operation which applies the mlp,\n",
    "    # i.e. the linear part, to each couple of n.n. and then\n",
    "    # aggregates the results.\n",
    "    # Expected output shape is [B, n, d] (aggregating we collapsed the k dimension)\n",
    "\n",
    "    '''Concateniamo le Features di due nearest neighbours, \n",
    "        passiamo questo Array alla parte lineare, \n",
    "        ripetiamo l'operazione per tutte le coppie di particella iesima e suo nearest neighbours,\n",
    "        facciamo max o softmax su queste\n",
    "    '''\n",
    "    for b in range(x.shape[0]): # scorro sui batch\n",
    "        x = [b, p, :, :]\n",
    "        for p in range(x.shape[1]): # fisso una particella\n",
    "            p_feat   = x[p, :, :]\n",
    "            print(p_feat.shape)\n",
    "            pairs = torch.stack([torch.stack([p_feat[0, :], p_feat[i, :]]) for i in range(0, x.shape[1])])\n",
    "            \n",
    "            print(\"pairs of the particle \",p, \"is\",pairs.shape) #expected [k, 2, d]\n",
    "\n",
    "            mlp_pair_list = []\n",
    "            # ciclo per accedere alle coppie\n",
    "            for i in range(pairs.shape[0]):\n",
    "                y = self.mlp(pairs[i, :, :]) # give to the MLP part a 2D tensor of shape [2,d]\n",
    "                mlp_pair_list.append(y)      # list of the i-esim particle with every its pairs\n",
    "            \n",
    "            print(\"len of pair list\",len(mlp_pair_list)) # expected k (number of pairs)\n",
    "\n",
    "            mlp_pair = torch.stack(mlp_pair_list) # aggregate all the pairs of the i-esim particle p\n",
    "            print(\"shape of all pairs output of layers\",mlp_pair.shape) # expected ??\n",
    "\n",
    "        particles_per_jet = torch.stack(mlp_pair) # aggregate all the particles of the jet\n",
    "        \n",
    "        '''\n",
    "        QUA CI SAREBBE IL SOFTMAX\n",
    "\n",
    "        '''\n",
    "        print(particles_per_jet.shape)\n",
    "    \"\"\"Aggregating for the batch\"\"\"\n",
    "\n",
    "    return None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60560e0d6226cb5287d81368c04acd3a7e9c5751a6dd0763b56dc9cf4b259ada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
